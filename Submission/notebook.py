# -*- coding: utf-8 -*-
"""Fuck_(1)_(1)_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gL1OF1_UT_J5iw2mzbR-_7z-6Vn5gvhX

# Proyek Klasifikasi Gambar: Butterfly Image Classification
- **Nama:** Lutfi Aundrie Hermawan
- **Email:** lutfiaunher@gmail.com
- **ID Dicoding:** A126YBF254

## Import Semua Packages/Library yang Digunakan
"""

# Library TensorFlow
!pip uninstall tensorflowjs
!pip install tensorflowjs

import tensorflow as tf
import tensorflowjs as tfjs
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, Flatten, Dropout, Dense,
    GlobalAveragePooling2D, BatchNormalization
)

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import EfficientNetV2B0, MobileNetV2
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v3 import preprocess_input

import os
import random
import shutil
import pathlib
import glob
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image
import cv2
import gdown
import absl.logging
import logging
import csv

"""## Data Preparation

Download Dataset melalui Google Drive

[Google Drive](https://drive.google.com/file/d/1UhgDkbQY_8PGlE98EuiXcP5kWjaiQnOW/view?usp=drive_link)

### Data Loading
"""

# Meload data pada Google Drive
file_id = '1UhgDkbQY_8PGlE98EuiXcP5kWjaiQnOW'

url = f'https://drive.google.com/uc?id={file_id}'
output = '/content/Dataset-Flowers.zip'

gdown.download(url, output, quiet=False)

"""### Data Preprocessing

#### Unzip Dataset and Remove Dataset .zip
"""

!unzip Dataset-Flowers.zip -d Dataset-Flowers/

remove_file = '/content/Dataset-Flowers.zip'
os.remove(remove_file)

"""#### Cek Keberagaman pada Dataset"""

import os
from PIL import Image

def count_images_and_resolution(base_path, target_resolution=None):
    class_count = {}
    resolution_count = {}

    for root, dirs, files in os.walk(base_path):
        if root == base_path:
            continue  # Lewati folder utama

        class_name = os.path.basename(root)
        class_count[class_name] = 0

        for file in files:
            if not file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
                continue  # Lewati jika bukan file gambar

            file_path = os.path.join(root, file)
            with Image.open(file_path) as img:
                width, height = img.size
                resolution = f"{width}x{height}"

                class_count[class_name] += 1

                if resolution not in resolution_count:
                    resolution_count[resolution] = 0
                resolution_count[resolution] += 1

                if target_resolution and resolution == target_resolution:
                    if 'target' not in resolution_count:
                        resolution_count['target'] = 0
                    resolution_count['target'] += 1

    return class_count, resolution_count

# Contoh penggunaan
base_path = "/content/Dataset-Flowers/"
target_resolution = "256x256"

class_count, resolution_count = count_images_and_resolution(base_path, target_resolution)

print("Jumlah gambar per kelas:")
for class_name, count in class_count.items():
    print(f"{class_name}: {count}")

print("\nJumlah gambar per resolusi:")
for resolution, count in resolution_count.items():
    print(f"{resolution}: {count}")

"""#### Cek Daftar Label pada Dataset"""

image_data='/content/Dataset-Flowers/train'
pd.DataFrame(os.listdir(image_data),columns=['Files_Name'])

image_test_data='/content/Dataset-Flowers/val'
pd.DataFrame(os.listdir(image_test_data),columns=['Files_Name'])

files = [i for i in glob.glob(image_data + "//*//*")]
np.random.shuffle(files)
labels = [os.path.dirname(i).split("/")[-1] for i in files]
data = zip(files, labels)
dataframe = pd.DataFrame(data, columns = ["Image", "Label"])
dataframe

# Bersihkan label
dataframe["Label"] = dataframe["Label"].str.strip()

# Hitung jumlah per label
label_counts = dataframe["Label"].value_counts().sort_index()

# Siapkan posisi bar dan value
x_pos = np.arange(len(label_counts))
counts = label_counts.values
labels = label_counts.index

# Plot bar
fig, ax = plt.subplots()
ax.bar(x_pos, counts, width=0.5)

ax.set_xticks(x_pos)
ax.set_xticklabels(labels, rotation=45, ha='right')
ax.set_ylabel('Jumlah')
ax.set_title('Distribusi Kelas Bunga')
ax.legend()

plt.tight_layout()
plt.show()

"""#### Combine Dataset"""

base_dir = 'Dataset-Flowers'
combined_dir = 'combined_dataset'

# Gabungkan semua gambar
os.makedirs(combined_dir, exist_ok=True)

for split in ['train', 'val']:
    split_path = os.path.join(base_dir, split)
    for class_name in os.listdir(split_path):
        class_path = os.path.join(split_path, class_name)
        if not os.path.isdir(class_path):
            continue

        new_class_path = os.path.join(combined_dir, class_name)
        os.makedirs(new_class_path, exist_ok=True)

        for img in os.listdir(class_path):
            src = os.path.join(class_path, img)
            dst = os.path.join(new_class_path, img)
            shutil.copy2(src, dst)

"""#### Split Dataset"""

# Folder gabungan sebelum split
combined_dir = 'combined_dataset'

# Folder baru untuk dataset split
split_base = 'dataset_split'
for split in ['train', 'val', 'test']:
    for class_name in os.listdir(combined_dir):
        os.makedirs(os.path.join(split_base, split, class_name), exist_ok=True)

# Folder test dibuat tanpa subfolder class
os.makedirs(os.path.join(split_base, 'test'), exist_ok=True)

# Atur rasio split
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# Split dan salin file
for class_name in os.listdir(combined_dir):
    class_dir = os.path.join(combined_dir, class_name)
    if not os.path.isdir(class_dir):
        continue

    images = os.listdir(class_dir)
    random.shuffle(images)

    total = len(images)
    train_end = int(total * train_ratio)
    val_end = train_end + int(total * val_ratio)

    train_imgs = images[:train_end]
    val_imgs = images[train_end:val_end]
    test_imgs = images[val_end:]

    for img in train_imgs:
        shutil.copy2(
            os.path.join(class_dir, img),
            os.path.join(split_base, 'train', class_name, img)
        )
    for img in val_imgs:
        shutil.copy2(
            os.path.join(class_dir, img),
            os.path.join(split_base, 'val', class_name, img)
        )
    for img in test_imgs:
        shutil.copy2(
            os.path.join(class_dir, img),
            os.path.join(split_base, 'test', class_name, img)
        )

"""#### Data Augmentasi Train"""

# Definisikan augmentasi
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

dataset_folder = '/content/dataset_split/train'

# Loop semua kelas (subfolder)
for class_name in os.listdir(dataset_folder):
    class_path = os.path.join(dataset_folder, class_name)

    if not os.path.isdir(class_path):
        continue  # Skip kalau bukan folder

    # Loop semua gambar dalam subfolder
    for img_name in os.listdir(class_path):
        img_path = os.path.join(class_path, img_name)

        try:
            # Load gambar
            img = load_img(img_path)
            x = img_to_array(img)
            x = np.expand_dims(x, axis=0)

            # Generate 1 augmentasi per gambar
            i = 0
            for batch in datagen.flow(
                x,
                batch_size=1,
                save_to_dir=class_path,         # <-- simpan ke folder asli
                save_prefix='aug',              # <-- prefix nama file baru
                save_format='jpg'                # <-- format gambar
            ):
                i += 1
                if i >= 1:  # <-- jumlah augmentasi per gambar
                    break
        except Exception as e:
            print(f"Error processing {img_path}: {e}")

"""#### Load Train, Val, Test"""

batch_size = 32
target_size = (224, 224)

# Load train dataset
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    directory=os.path.join('/content/dataset_split/train'),
    label_mode='categorical',  # pakai categorical kalau multi-class
    image_size=target_size,
    batch_size=batch_size,
    shuffle=True,
    seed=123
)

# Load validation dataset
val_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    directory=os.path.join('/content/dataset_split/val'),
    label_mode='categorical',
    image_size=target_size,
    batch_size=batch_size,
    shuffle=False,
    seed=123
)

# Load test dataset
test_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    directory=os.path.join('/content/dataset_split/test'),
    label_mode='categorical',
    image_size=target_size,
    batch_size=batch_size,
    shuffle=False,
    seed=123
)

"""## Class Weights"""

def calculate_class_weights(y_labels, class_names):
    unique_classes, class_counts = np.unique(y_labels, return_counts=True)
    total_samples = len(y_labels)
    class_weights = {}

    # Create weights for all classes in class_names, even if not in train data
    for class_name in class_names:
        if class_name in unique_classes:  # If class is in train data
            class_index = np.where(unique_classes == class_name)[0][0]
            class_count = class_counts[class_index]
            weight = total_samples / (len(unique_classes) * class_count)
            class_weights[class_name] = round(weight, 2)
        else:  # If class is not in train data, give it a default weight (e.g., 1)
            class_weights[class_name] = 1.0

    return class_weights

# Extract labels from the train dataset
y_labels = []
for images, labels in train_dataset:  # Iterate through batches
    y_labels.extend(np.argmax(labels.numpy(), axis=1))  # Get class indices from one-hot encoded labels

# Get class names from the train dataset
class_names = train_dataset.class_names  # Access class names directly

# Calculate class weights using the updated function
raw_class_weights = calculate_class_weights(y_labels, class_names)  # Pass class_names to the function


# Create a dictionary mapping class indices to weights
indexed_class_weights = {i: raw_class_weights[class_name] for i, class_name in enumerate(class_names)}

print("Class weights (siap pakai untuk model):")
for idx, weight in indexed_class_weights.items():
    # Use the index to get the corresponding label
    label = class_names[idx]
    print(f"Index {idx} (Label '{label}'): {weight}")

"""## Modelling

### Model Sequential, Conv2D, Pooling Layer
"""

#base_model = tf.keras.applications.MobileNetV2(
#    weights='imagenet',
#    include_top=False,
#    input_shape=(224, 224, 3)
#)

base_model = tf.keras.applications.MobileNetV3Large(input_shape=(224,224,3), include_top=False, weights='imagenet')
base_model.trainable = False

#base_model.trainable = False  # freeze pretrained VGG16

keras_model = tf.keras.models.Sequential([
    #tf.keras.Input(shape=(224,224,3)),
    base_model,

    # 2nd Block
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    #tf.keras.layers.BatchNormalization(),
    #tf.keras.layers.LeakyReLU(),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.3),

    # 3nd Block
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    #tf.keras.layers.BatchNormalization(),
    #tf.keras.layers.LeakyReLU(),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Dropout(0.3),

    # Fully Connected
    tf.keras.layers.Flatten(),

    #tf.keras.layers.Dense(512),
    #tf.keras.layers.LeakyReLU(),
    #tf.keras.layers.Dropout(0.5),

    #tf.keras.layers.Dense(256),
    #tf.keras.layers.BatchNormalization(),
    #tf.keras.layers.LeakyReLU(),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Dense(14, activation='softmax')
])

# Print model summary
keras_model.summary()

tf.keras.utils.plot_model(keras_model, to_file='model.jpg', show_shapes=True, show_layer_names=True,show_dtype=True,dpi=80)

"""### Callback"""

checkpoint = ModelCheckpoint("my_keras_model.keras", save_best_only=True)
early_stopping = EarlyStopping(patience=6, restore_best_weights=True)

optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)

keras_model.compile(
    optimizer=optimizer,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

"""### Train Validation Model"""

history = keras_model.fit(
    train_dataset,
    epochs=40,
    validation_data=val_dataset,
    callbacks=[checkpoint, early_stopping],
    class_weight=indexed_class_weights
)

"""## Evaluasi dan Visualisasi

### A. Evaluasi Model di Data Test
"""

loss, accuracy = keras_model.evaluate(test_dataset)
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Loss: {loss:.4f}")

"""### B. Visualisasi Model"""

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy per Epoch')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss per Epoch')
plt.legend()
plt.show()

"""## Konversi Model

### Saved Model
"""

keras_model.export("saved_model/my_model")

"""### TF-Lite"""

# 1. Konversi SavedModel ke TFLite
converter = tf.lite.TFLiteConverter.from_saved_model("saved_model/my_model")
tflite_model = converter.convert()

# 2. Buat folder simpan model TFLite
os.makedirs('tflite', exist_ok=True)

# 3. Simpan model .tflite
with open('tflite/model.tflite', 'wb') as f:
    f.write(tflite_model)

print("Model berhasil dikonversi ke TFLite dan disimpan sebagai 'tflite/model.tflite'")

# 4. Simpan file label (klasifikasi 14 jenis bunga)
class_names = [
    'astilbe', 'bellflower', 'black_eyed_susan', 'calendula', 'california_poppy',
    'carnation', 'common_daisy', 'coreopsis', 'dandelion', 'iris',
    'rose', 'sunflower', 'tulip', 'water_lily'
]

with open('tflite/label.txt', 'w') as f:
    for name in class_names:
        f.write(name + '\n')

print("Label berhasil disimpan sebagai 'tflite/label.txt'")

"""### TFJS"""

!tensorflowjs_converter \
    --input_format=tf_saved_model \
    --output_format=tfjs_graph_model \
    --signature_name=serving_default \
    --saved_model_tags=serve \
    saved_model/my_model \
    tfjs_model

"""### pip Freeze"""

!pip freeze > requirements.txt

"""## Inference (Optional)"""

def predict_and_display(img_path, interpreter, class_names):
    # Load dan preprocess image
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    # Get input and output details
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # Set input tensor and invoke the interpreter
    interpreter.set_tensor(input_details[0]['index'], img_array)
    interpreter.invoke()

    # Get the output tensor
    predictions = interpreter.get_tensor(output_details[0]['index'])

    # Get predicted class
    predicted_class = np.argmax(predictions, axis=1)
    predicted_label = class_names[predicted_class[0]]

    # Display the image and prediction
    plt.imshow(img)
    plt.title(f'Predicted: {predicted_label}')
    plt.axis('off')
    plt.show()

# Load interpreter
interpreter = tf.lite.Interpreter(model_path='tflite/model.tflite')
interpreter.allocate_tensors()

def check_image_infolder(img_path):
    if not os.path.isfile(img_path):
        all_images = glob.glob("/content/dataset_split/test/**/*.jpg", recursive=True)
        img_path = random.choice(all_images)
        print(f"Using image: {img_path}")
    else :
        print(f"Using image: {img_path}")

    return img_path

# Load image for test
Image_One = check_image_infolder("/content/dataset_split/test/black_eyed_susan/1057222299_1389a4723e_c.jpg")
predict_and_display(Image_One, interpreter, class_names)

Image_Two = check_image_infolder("/content/dataset_split/test/tulip/10400415455_7a4796d598_c.jpg")
predict_and_display(Image_Two, interpreter, class_names)

Image_Three = check_image_infolder("/content/dataset_split/test/dandelion/10774849493_bb82957f1b_c.jpg")
predict_and_display(Image_Three, interpreter, class_names)

!zip -r /content/saved_model.zip /content/saved_model

!zip -r /content/tfjs_model.zip /content/tfjs_model

!zip -r /content/tflite.zip /content/tflite